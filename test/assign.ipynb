{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrrphsCavo6tnhbS9dG1Sv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbooeshaghi/mx/blob/master/test/assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKTJTwTt3OF0",
        "outputId": "d961a589-231d-4e17-9bd6-1a611c321e25"
      },
      "source": [
        "!pip install --quiet -U upsetplot scikit-learn "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 23.2 MB 45.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhXedfjH1OAb",
        "outputId": "49f13aed-9169-4dd0-d221-54af383e3941"
      },
      "source": [
        "!python -m pip show scikit-learn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: scikit-learn\n",
            "Version: 1.0.1\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: numpy, scipy, threadpoolctl, joblib\n",
            "Required-by: yellowbrick, sklearn, sklearn-pandas, mlxtend, lightgbm, librosa, imbalanced-learn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0UcVgt9IiBw",
        "outputId": "28c71dcc-bf41-4665-f543-525171dd9e1c"
      },
      "source": [
        "# access token will expire 26 November 2021\n",
        "!git clone https://sbooeshaghi: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@github.com/cellatlas/human.git\n",
        "# https://stackoverflow.com/a/52269934/13731947\n",
        "# sparse clone (look into this)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'human'...\n",
            "remote: Enumerating objects: 862, done.\u001b[K\n",
            "remote: Total 862 (delta 0), reused 0 (delta 0), pack-reused 862\u001b[K\n",
            "Receiving objects: 100% (862/862), 724.64 MiB | 40.27 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "Checking out files: 100% (149/149), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "XdWJz5JEIpxR"
      },
      "source": [
        "#@title index.py\n",
        "%%bash\n",
        "echo \"#!/usr/bin/env python3\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def write_dict(fname, d):\n",
        "    inv_d = {v: k for k, v in d.items()}\n",
        "    with open(fname, 'w') as f:\n",
        "        for idx in range(len(d)):\n",
        "            f.write(f'{inv_d[idx]}\\n')\n",
        "\n",
        "\n",
        "def write_markers(fname, markers):\n",
        "    with open(fname, 'w') as f:\n",
        "        for k, v in markers.items():\n",
        "            f.write(f'{k}\\t')\n",
        "            n = len(v)\n",
        "            for idx, i in enumerate(v):\n",
        "                f.write(f'{i}')\n",
        "                if idx < n - 1:\n",
        "                    f.write(',')\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "def read_markers(fname,\n",
        "                 markers_ec=defaultdict(list),\n",
        "                 celltype=defaultdict(),\n",
        "                 marker_genes=defaultdict()):\n",
        "    with open(fname, 'r') as f:\n",
        "        for idx, line in enumerate(f.readlines()):\n",
        "            ct, genes = line.strip().split('\\t')\n",
        "            celltype[ct] = idx\n",
        "\n",
        "            # two things\n",
        "            # 1. make marker_genes list\n",
        "            # 2. make markers_ec\n",
        "            for g in genes.split(','):\n",
        "                gidx = len(marker_genes)\n",
        "\n",
        "                # check if the gene has been added already\n",
        "                if g in marker_genes.keys():  # gene repeated\n",
        "                    gidx = marker_genes[g]\n",
        "                else:\n",
        "                    marker_genes[g] = gidx\n",
        "\n",
        "                # for the cell type index, add the marker gene index\n",
        "                markers_ec[celltype[ct]].append(marker_genes[g])\n",
        "\n",
        "            # sort the marker genes\n",
        "            markers_ec[celltype[ct]] = sorted(markers_ec[celltype[ct]])\n",
        "\n",
        "\n",
        "def main(markers_fname, outdir):\n",
        "    markers_ec = defaultdict(list)\n",
        "    celltypes = defaultdict()\n",
        "    marker_genes = defaultdict()\n",
        "    read_markers(markers_fname, markers_ec, celltypes, marker_genes)\n",
        "\n",
        "    write_markers(os.path.join(outdir, 'markers.ec'), markers_ec)\n",
        "    write_dict(os.path.join(outdir, 'types.txt'), celltypes)\n",
        "    write_dict(os.path.join(outdir, 'marker_genes.txt'), marker_genes)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    markers_fname = sys.argv[1]\n",
        "    outdir = sys.argv[2]\n",
        "    main(markers_fname, outdir)\n",
        "\n",
        "\" > index.py\n",
        "\n",
        "chmod +x index.py"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wyNcv0--JDMP"
      },
      "source": [
        "#@title select.py\n",
        "%%bash\n",
        "echo \"#!/usr/bin/env python3\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def read_markers(fname,\n",
        "                 markers_ec=defaultdict(list),\n",
        "                 celltype=defaultdict(),\n",
        "                 marker_genes=defaultdict()):\n",
        "    with open(fname, 'r') as f:\n",
        "        for idx, line in enumerate(f.readlines()):\n",
        "            ct, genes = line.strip().split('\\t')\n",
        "            celltype[ct] = idx\n",
        "\n",
        "            # two things\n",
        "            # 1. make marker_genes list\n",
        "            # 2. make markers_ec\n",
        "            for g in genes.split(','):\n",
        "                gidx = len(marker_genes)\n",
        "\n",
        "                # check if the gene has been added already\n",
        "                if g in marker_genes.keys():  # gene repeated\n",
        "                    gidx = marker_genes[g]\n",
        "                else:\n",
        "                    marker_genes[g] = gidx\n",
        "\n",
        "                # for the cell type index, add the marker gene index\n",
        "                markers_ec[celltype[ct]].append(marker_genes[g])\n",
        "\n",
        "            # sort the marker genes\n",
        "            markers_ec[celltype[ct]] = sorted(markers_ec[celltype[ct]])\n",
        "\n",
        "\n",
        "def read_genes(genes_fname, genes=defaultdict()):\n",
        "    with open(genes_fname) as f:\n",
        "        for idx, line in enumerate(f.readlines()):\n",
        "            gene = line.strip()\n",
        "            genes[gene] = idx\n",
        "\n",
        "\n",
        "def sel_genes(genes, marker_genes, sel=[]):\n",
        "    mg_inv = {v: k for k, v in marker_genes.items()}\n",
        "    for idx in range(len(mg_inv)):\n",
        "        # this maps the marker gene name index to the gene index\n",
        "        # in order of the marker_genes file\n",
        "        sel.append(genes[mg_inv[idx]])\n",
        "\n",
        "\n",
        "def write_list(fname, lst):\n",
        "    with open(fname, 'w') as f:\n",
        "        for el in lst:\n",
        "            f.write(f'{el}\\n')\n",
        "\n",
        "\n",
        "def main(markers_fname, genes_fname, outdir):\n",
        "    markers_ec = defaultdict(list)\n",
        "    celltypes = defaultdict()\n",
        "    marker_genes = defaultdict()\n",
        "    # this is duplicated from index, not ideal but w/e maybe ok\n",
        "    # ideally would want to give it markers.ec\n",
        "    read_markers(markers_fname, markers_ec, celltypes, marker_genes)\n",
        "\n",
        "    genes = defaultdict()\n",
        "    read_genes(genes_fname, genes)\n",
        "\n",
        "    sel = []\n",
        "    sel_genes(genes, marker_genes, sel)\n",
        "    write_list(os.path.join(outdir, 'select.txt'), sel)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    markers_fname = sys.argv[1]\n",
        "    genes_fname = sys.argv[2]\n",
        "    outdir = sys.argv[3]\n",
        "    main(markers_fname, genes_fname, outdir)\n",
        "\n",
        "\" > select.py\n",
        "\n",
        "chmod +x ./select.py"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-j38efKcJLki"
      },
      "source": [
        "#@title sklearn/mixture/_base.py\n",
        "\n",
        "\"\"\"Base class for mixture models.\"\"\"\n",
        "\n",
        "# sklearn/mixture/_base.py\n",
        "\n",
        "# Author: Wei Xue <xuewei4d@gmail.com>\n",
        "# Modified by Thierry Guillemot <thierry.guillemot.work@gmail.com>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import warnings\n",
        "from abc import ABCMeta, abstractmethod\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "from sklearn import cluster\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import DensityMixin\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "\n",
        "def _check_shape(param, param_shape, name):\n",
        "    \"\"\"Validate the shape of the input parameter 'param'.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    param : array\n",
        "\n",
        "    param_shape : tuple\n",
        "\n",
        "    name : str\n",
        "    \"\"\"\n",
        "    param = np.array(param)\n",
        "    if param.shape != param_shape:\n",
        "        raise ValueError(\n",
        "            \"The parameter '%s' should have the shape of %s, but got %s\" %\n",
        "            (name, param_shape, param.shape))\n",
        "\n",
        "\n",
        "class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n",
        "    \"\"\"Base class for mixture models.\n",
        "\n",
        "    This abstract class specifies an interface for all mixture classes and\n",
        "    provides basic common methods for mixture models.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_components,\n",
        "        tol,\n",
        "        reg_covar,\n",
        "        max_iter,\n",
        "        n_init,\n",
        "        init_params,\n",
        "        random_state,\n",
        "        warm_start,\n",
        "        verbose,\n",
        "        verbose_interval,\n",
        "    ):\n",
        "        self.n_components = n_components\n",
        "        self.tol = tol\n",
        "        self.reg_covar = reg_covar\n",
        "        self.max_iter = max_iter\n",
        "        self.n_init = n_init\n",
        "        self.init_params = init_params\n",
        "        self.random_state = random_state\n",
        "        self.warm_start = warm_start\n",
        "        self.verbose = verbose\n",
        "        self.verbose_interval = verbose_interval\n",
        "\n",
        "    def _check_initial_parameters(self, X):\n",
        "        \"\"\"Check values of the basic parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "        \"\"\"\n",
        "        if self.n_components < 1:\n",
        "            raise ValueError(\"Invalid value for 'n_components': %d \"\n",
        "                             \"Estimation requires at least one component\" %\n",
        "                             self.n_components)\n",
        "\n",
        "        if self.tol < 0.0:\n",
        "            raise ValueError(\"Invalid value for 'tol': %.5f \"\n",
        "                             \"Tolerance used by the EM must be non-negative\" %\n",
        "                             self.tol)\n",
        "\n",
        "        if self.n_init < 1:\n",
        "            raise ValueError(\n",
        "                \"Invalid value for 'n_init': %d Estimation requires at least one run\"\n",
        "                % self.n_init)\n",
        "\n",
        "        if self.max_iter < 1:\n",
        "            raise ValueError(\"Invalid value for 'max_iter': %d \"\n",
        "                             \"Estimation requires at least one iteration\" %\n",
        "                             self.max_iter)\n",
        "\n",
        "        if self.reg_covar < 0.0:\n",
        "            raise ValueError(\"Invalid value for 'reg_covar': %.5f \"\n",
        "                             \"regularization on covariance must be \"\n",
        "                             \"non-negative\" % self.reg_covar)\n",
        "\n",
        "        # Check all the parameters values of the derived class\n",
        "        self._check_parameters(X)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _check_parameters(self, X):\n",
        "        \"\"\"Check initial parameters of the derived class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape  (n_samples, n_features)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def _initialize_parameters(self, X, random_state, B=None, resp=None):\n",
        "        \"\"\"Initialize the model parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape  (n_samples, n_features)\n",
        "\n",
        "        random_state : RandomState\n",
        "            A random number generator instance that controls the random seed\n",
        "            used for the method chosen to initialize the parameters.\n",
        "        \"\"\"\n",
        "        n_samples, _ = X.shape\n",
        "\n",
        "        if self.init_params == \"kmeans\":\n",
        "            resp = np.zeros((n_samples, self.n_components))\n",
        "            label = (cluster.KMeans(n_clusters=self.n_components,\n",
        "                                    n_init=1,\n",
        "                                    random_state=random_state).fit(X).labels_)\n",
        "            resp[np.arange(n_samples), label] = 1\n",
        "        elif self.init_params == \"random\":\n",
        "          if resp is None:\n",
        "            resp = random_state.rand(n_samples, self.n_components)\n",
        "            resp /= resp.sum(axis=1)[:, np.newaxis]\n",
        "        else:\n",
        "            raise ValueError(\"Unimplemented initialization method '%s'\" %\n",
        "                             self.init_params)\n",
        "\n",
        "        self._initialize(X, resp, B)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _initialize(self, X, resp, B=None):\n",
        "        \"\"\"Initialize the model parameters of the derived class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape  (n_samples, n_features)\n",
        "\n",
        "        resp : array-like of shape (n_samples, n_components)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Estimate model parameters with the EM algorithm.\n",
        "\n",
        "        The method fits the model ``n_init`` times and sets the parameters with\n",
        "        which the model has the largest likelihood or lower bound. Within each\n",
        "        trial, the method iterates between E-step and M-step for ``max_iter``\n",
        "        times until the change of likelihood or lower bound is less than\n",
        "        ``tol``, otherwise, a ``ConvergenceWarning`` is raised.\n",
        "        If ``warm_start`` is ``True``, then ``n_init`` is ignored and a single\n",
        "        initialization is performed upon the first call. Upon consecutive\n",
        "        calls, training starts where it left off.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        y : Ignored\n",
        "            Not used, present for API consistency by convention.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            The fitted mixture.\n",
        "        \"\"\"\n",
        "        self.fit_predict(X, y)\n",
        "        return self\n",
        "\n",
        "    def fit_predict(self, X, y=None, B=None, resp=None):\n",
        "        \"\"\"Estimate model parameters using X and predict the labels for X.\n",
        "\n",
        "        The method fits the model n_init times and sets the parameters with\n",
        "        which the model has the largest likelihood or lower bound. Within each\n",
        "        trial, the method iterates between E-step and M-step for `max_iter`\n",
        "        times until the change of likelihood or lower bound is less than\n",
        "        `tol`, otherwise, a :class:`~sklearn.exceptions.ConvergenceWarning` is\n",
        "        raised. After fitting, it predicts the most probable label for the\n",
        "        input data points.\n",
        "\n",
        "        .. versionadded:: 0.20\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        y : Ignored\n",
        "            Not used, present for API consistency by convention.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        labels : array, shape (n_samples,)\n",
        "            Component labels.\n",
        "        \"\"\"\n",
        "        X = self._validate_data(X,\n",
        "                                dtype=[np.float64, np.float32],\n",
        "                                ensure_min_samples=2)\n",
        "        if X.shape[0] < self.n_components:\n",
        "            raise ValueError(\"Expected n_samples >= n_components \"\n",
        "                             f\"but got n_components = {self.n_components}, \"\n",
        "                             f\"n_samples = {X.shape[0]}\")\n",
        "        self._check_initial_parameters(X)\n",
        "\n",
        "        # if we enable warm_start, we will have a unique initialisation\n",
        "        do_init = not (self.warm_start and hasattr(self, \"converged_\"))\n",
        "        n_init = self.n_init if do_init else 1\n",
        "\n",
        "        max_lower_bound = -np.inf\n",
        "        self.converged_ = False\n",
        "\n",
        "        random_state = check_random_state(self.random_state)\n",
        "\n",
        "        n_samples, _ = X.shape\n",
        "        for init in range(n_init):\n",
        "            self._print_verbose_msg_init_beg(init)\n",
        "\n",
        "            if do_init:\n",
        "                self._initialize_parameters(X, random_state, B=B, resp=resp)\n",
        "\n",
        "            lower_bound = -np.inf if do_init else self.lower_bound_\n",
        "\n",
        "            for n_iter in range(1, self.max_iter + 1):\n",
        "                prev_lower_bound = lower_bound\n",
        "\n",
        "                log_prob_norm, log_resp = self._e_step(X)\n",
        "                self._m_step(X, log_resp, B)\n",
        "                lower_bound = self._compute_lower_bound(\n",
        "                    log_resp, log_prob_norm)\n",
        "\n",
        "                change = lower_bound - prev_lower_bound\n",
        "                self._print_verbose_msg_iter_end(n_iter, change)\n",
        "\n",
        "                if abs(change) < self.tol:\n",
        "                    self.converged_ = True\n",
        "                    break\n",
        "\n",
        "            self._print_verbose_msg_init_end(lower_bound)\n",
        "\n",
        "            if lower_bound > max_lower_bound or max_lower_bound == -np.inf:\n",
        "                max_lower_bound = lower_bound\n",
        "                best_params = self._get_parameters()\n",
        "                best_n_iter = n_iter\n",
        "\n",
        "        if not self.converged_:\n",
        "            warnings.warn(\n",
        "                \"Initialization %d did not converge. \"\n",
        "                \"Try different init parameters, \"\n",
        "                \"or increase max_iter, tol \"\n",
        "                \"or check for degenerate data.\" % (init + 1),\n",
        "                ConvergenceWarning,\n",
        "            )\n",
        "\n",
        "        self._set_parameters(best_params)\n",
        "        self.n_iter_ = best_n_iter\n",
        "        self.lower_bound_ = max_lower_bound\n",
        "\n",
        "        # Always do a final e-step to guarantee that the labels returned by\n",
        "        # fit_predict(X) are always consistent with fit(X).predict(X)\n",
        "        # for any value of max_iter and tol (and any random_state).\n",
        "        _, log_resp = self._e_step(X)\n",
        "\n",
        "        return log_resp.argmax(axis=1)\n",
        "\n",
        "    def _e_step(self, X):\n",
        "        \"\"\"E step.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_prob_norm : float\n",
        "            Mean of the logarithms of the probabilities of each sample in X\n",
        "\n",
        "        log_responsibility : array, shape (n_samples, n_components)\n",
        "            Logarithm of the posterior probabilities (or responsibilities) of\n",
        "            the point of each sample in X.\n",
        "        \"\"\"\n",
        "        log_prob_norm, log_resp = self._estimate_log_prob_resp(X)\n",
        "        return np.mean(log_prob_norm), log_resp\n",
        "\n",
        "    @abstractmethod\n",
        "    def _m_step(self, X, log_resp, B=None):\n",
        "        \"\"\"M step.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        log_resp : array-like of shape (n_samples, n_components)\n",
        "            Logarithm of the posterior probabilities (or responsibilities) of\n",
        "            the point of each sample in X.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _get_parameters(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _set_parameters(self, params):\n",
        "        pass\n",
        "\n",
        "    def score_samples(self, X):\n",
        "        \"\"\"Compute the log-likelihood of each sample.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_prob : array, shape (n_samples,)\n",
        "            Log-likelihood of each sample in `X` under the current model.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_data(X, reset=False)\n",
        "\n",
        "        return logsumexp(self._estimate_weighted_log_prob(X), axis=1)\n",
        "\n",
        "    def score(self, X, y=None):\n",
        "        \"\"\"Compute the per-sample average log-likelihood of the given data X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_dimensions)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        y : Ignored\n",
        "            Not used, present for API consistency by convention.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_likelihood : float\n",
        "            Log-likelihood of `X` under the Gaussian mixture model.\n",
        "        \"\"\"\n",
        "        return self.score_samples(X).mean()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for the data samples in X using trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        labels : array, shape (n_samples,)\n",
        "            Component labels.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_data(X, reset=False)\n",
        "        return self._estimate_weighted_log_prob(X).argmax(axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Evaluate the components' density for each sample.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            List of n_features-dimensional data points. Each row\n",
        "            corresponds to a single data point.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        resp : array, shape (n_samples, n_components)\n",
        "            Density of each Gaussian component for each sample in X.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = self._validate_data(X, reset=False)\n",
        "        _, log_resp = self._estimate_log_prob_resp(X)\n",
        "        return np.exp(log_resp)\n",
        "\n",
        "    def sample(self, n_samples=1):\n",
        "        \"\"\"Generate random samples from the fitted Gaussian distribution.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_samples : int, default=1\n",
        "            Number of samples to generate.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X : array, shape (n_samples, n_features)\n",
        "            Randomly generated sample.\n",
        "\n",
        "        y : array, shape (nsamples,)\n",
        "            Component labels.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        if n_samples < 1:\n",
        "            raise ValueError(\n",
        "                \"Invalid value for 'n_samples': %d . The sampling requires at \"\n",
        "                \"least one sample.\" % (self.n_components))\n",
        "\n",
        "        _, n_features = self.means_.shape\n",
        "        rng = check_random_state(self.random_state)\n",
        "        n_samples_comp = rng.multinomial(n_samples, self.weights_)\n",
        "\n",
        "        if self.covariance_type == \"full\":\n",
        "            X = np.vstack([\n",
        "                rng.multivariate_normal(mean, covariance, int(sample))\n",
        "                for (mean, covariance, sample\n",
        "                     ) in zip(self.means_, self.covariances_, n_samples_comp)\n",
        "            ])\n",
        "        elif self.covariance_type == \"tied\":\n",
        "            X = np.vstack([\n",
        "                rng.multivariate_normal(mean, self.covariances_, int(sample))\n",
        "                for (mean, sample) in zip(self.means_, n_samples_comp)\n",
        "            ])\n",
        "        else:\n",
        "            X = np.vstack([\n",
        "                mean + rng.randn(sample, n_features) * np.sqrt(covariance)\n",
        "                for (mean, covariance, sample\n",
        "                     ) in zip(self.means_, self.covariances_, n_samples_comp)\n",
        "            ])\n",
        "\n",
        "        y = np.concatenate([\n",
        "            np.full(sample, j, dtype=int)\n",
        "            for j, sample in enumerate(n_samples_comp)\n",
        "        ])\n",
        "\n",
        "        return (X, y)\n",
        "\n",
        "    def _estimate_weighted_log_prob(self, X):\n",
        "        \"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        weighted_log_prob : array, shape (n_samples, n_component)\n",
        "        \"\"\"\n",
        "        return self._estimate_log_prob(X) + self._estimate_log_weights()\n",
        "\n",
        "    @abstractmethod\n",
        "    def _estimate_log_weights(self):\n",
        "        \"\"\"Estimate log-weights in EM algorithm, E[ log pi ] in VB algorithm.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_weight : array, shape (n_components, )\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _estimate_log_prob(self, X):\n",
        "        \"\"\"Estimate the log-probabilities log P(X | Z).\n",
        "\n",
        "        Compute the log-probabilities per each component for each sample.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_prob : array, shape (n_samples, n_component)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def _estimate_log_prob_resp(self, X):\n",
        "        \"\"\"Estimate log probabilities and responsibilities for each sample.\n",
        "\n",
        "        Compute the log probabilities, weighted log probabilities per\n",
        "        component and responsibilities for each sample in X with respect to\n",
        "        the current state of the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        log_prob_norm : array, shape (n_samples,)\n",
        "            log p(X)\n",
        "\n",
        "        log_responsibilities : array, shape (n_samples, n_components)\n",
        "            logarithm of the responsibilities\n",
        "        \"\"\"\n",
        "        weighted_log_prob = self._estimate_weighted_log_prob(X)\n",
        "        log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
        "        with np.errstate(under=\"ignore\"):\n",
        "            # ignore underflow\n",
        "            log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
        "        return log_prob_norm, log_resp\n",
        "\n",
        "    def _print_verbose_msg_init_beg(self, n_init):\n",
        "        \"\"\"Print verbose message on initialization.\"\"\"\n",
        "        if self.verbose == 1:\n",
        "            print(\"Initialization %d\" % n_init)\n",
        "        elif self.verbose >= 2:\n",
        "            print(\"Initialization %d\" % n_init)\n",
        "            self._init_prev_time = time()\n",
        "            self._iter_prev_time = self._init_prev_time\n",
        "\n",
        "    def _print_verbose_msg_iter_end(self, n_iter, diff_ll):\n",
        "        \"\"\"Print verbose message on initialization.\"\"\"\n",
        "        if n_iter % self.verbose_interval == 0:\n",
        "            if self.verbose == 1:\n",
        "                print(\"  Iteration %d\" % n_iter)\n",
        "            elif self.verbose >= 2:\n",
        "                cur_time = time()\n",
        "                print(\"  Iteration %d\\t time lapse %.5fs\\t ll change %.5f\" %\n",
        "                      (n_iter, cur_time - self._iter_prev_time, diff_ll))\n",
        "                self._iter_prev_time = cur_time\n",
        "\n",
        "    def _print_verbose_msg_init_end(self, ll):\n",
        "        \"\"\"Print verbose message on the end of iteration.\"\"\"\n",
        "        if self.verbose == 1:\n",
        "            print(\"Initialization converged: %s\" % self.converged_)\n",
        "        elif self.verbose >= 2:\n",
        "            print(\"Initialization converged: %s\\t time lapse %.5fs\\t ll %.5f\" %\n",
        "                  (self.converged_, time() - self._init_prev_time, ll))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xMiE1A6KJUXH"
      },
      "source": [
        "#@title sklearn/mixture/_gaussian_mixture.py \n",
        "\n",
        "\"\"\"Gaussian Mixture Model.\"\"\"\n",
        "\n",
        "# sklearn/mixture/_gaussian_mixture.py \n",
        "\n",
        "# Author: Wei Xue <xuewei4d@gmail.com>\n",
        "# Modified by Thierry Guillemot <thierry.guillemot.work@gmail.com>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy import linalg\n",
        "\n",
        "# from ._base import BaseMixture, _check_shape these come from cell above\n",
        "from sklearn.utils import check_array\n",
        "from sklearn.utils.extmath import row_norms\n",
        "\n",
        "###############################################################################\n",
        "# Gaussian mixture shape checkers used by the GaussianMixture class\n",
        "\n",
        "\n",
        "def _check_weights(weights, n_components):\n",
        "    \"\"\"Check the user provided 'weights'.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    weights : array-like of shape (n_components,)\n",
        "        The proportions of components of each mixture.\n",
        "\n",
        "    n_components : int\n",
        "        Number of components.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    weights : array, shape (n_components,)\n",
        "    \"\"\"\n",
        "    weights = check_array(weights,\n",
        "                          dtype=[np.float64, np.float32],\n",
        "                          ensure_2d=False)\n",
        "    _check_shape(weights, (n_components, ), \"weights\")\n",
        "\n",
        "    # check range\n",
        "    if any(np.less(weights, 0.0)) or any(np.greater(weights, 1.0)):\n",
        "        raise ValueError(\"The parameter 'weights' should be in the range \"\n",
        "                         \"[0, 1], but got max value %.5f, min value %.5f\" %\n",
        "                         (np.min(weights), np.max(weights)))\n",
        "\n",
        "    # check normalization\n",
        "    if not np.allclose(np.abs(1.0 - np.sum(weights)), 0.0):\n",
        "        raise ValueError(\n",
        "            \"The parameter 'weights' should be normalized, but got sum(weights) = %.5f\"\n",
        "            % np.sum(weights))\n",
        "    return weights\n",
        "\n",
        "\n",
        "def _check_means(means, n_components, n_features):\n",
        "    \"\"\"Validate the provided 'means'.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "        The centers of the current components.\n",
        "\n",
        "    n_components : int\n",
        "        Number of components.\n",
        "\n",
        "    n_features : int\n",
        "        Number of features.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    means : array, (n_components, n_features)\n",
        "    \"\"\"\n",
        "    means = check_array(means, dtype=[np.float64, np.float32], ensure_2d=False)\n",
        "    _check_shape(means, (n_components, n_features), \"means\")\n",
        "    return means\n",
        "\n",
        "\n",
        "def _check_precision_positivity(precision, covariance_type):\n",
        "    \"\"\"Check a precision vector is positive-definite.\"\"\"\n",
        "    if np.any(np.less_equal(precision, 0.0)):\n",
        "        raise ValueError(\"'%s precision' should be positive\" % covariance_type)\n",
        "\n",
        "\n",
        "def _check_precision_matrix(precision, covariance_type):\n",
        "    \"\"\"Check a precision matrix is symmetric and positive-definite.\"\"\"\n",
        "    if not (np.allclose(precision, precision.T)\n",
        "            and np.all(linalg.eigvalsh(precision) > 0.0)):\n",
        "        raise ValueError(\n",
        "            \"'%s precision' should be symmetric, positive-definite\" %\n",
        "            covariance_type)\n",
        "\n",
        "\n",
        "def _check_precisions_full(precisions, covariance_type):\n",
        "    \"\"\"Check the precision matrices are symmetric and positive-definite.\"\"\"\n",
        "    for prec in precisions:\n",
        "        _check_precision_matrix(prec, covariance_type)\n",
        "\n",
        "\n",
        "def _check_precisions(precisions, covariance_type, n_components, n_features):\n",
        "    \"\"\"Validate user provided precisions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    precisions : array-like\n",
        "        'full' : shape of (n_components, n_features, n_features)\n",
        "        'tied' : shape of (n_features, n_features)\n",
        "        'diag' : shape of (n_components, n_features)\n",
        "        'spherical' : shape of (n_components,)\n",
        "\n",
        "    covariance_type : str\n",
        "\n",
        "    n_components : int\n",
        "        Number of components.\n",
        "\n",
        "    n_features : int\n",
        "        Number of features.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    precisions : array\n",
        "    \"\"\"\n",
        "    precisions = check_array(\n",
        "        precisions,\n",
        "        dtype=[np.float64, np.float32],\n",
        "        ensure_2d=False,\n",
        "        allow_nd=covariance_type == \"full\",\n",
        "    )\n",
        "\n",
        "    precisions_shape = {\n",
        "        \"full\": (n_components, n_features, n_features),\n",
        "        \"tied\": (n_features, n_features),\n",
        "        \"diag\": (n_components, n_features),\n",
        "        \"spherical\": (n_components, ),\n",
        "    }\n",
        "    _check_shape(precisions, precisions_shape[covariance_type],\n",
        "                 \"%s precision\" % covariance_type)\n",
        "\n",
        "    _check_precisions = {\n",
        "        \"full\": _check_precisions_full,\n",
        "        \"tied\": _check_precision_matrix,\n",
        "        \"diag\": _check_precision_positivity,\n",
        "        \"spherical\": _check_precision_positivity,\n",
        "    }\n",
        "    _check_precisions[covariance_type](precisions, covariance_type)\n",
        "    return precisions\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Gaussian mixture parameters estimators (used by the M-Step)\n",
        "\n",
        "\n",
        "def _estimate_gaussian_covariances_full(resp, X, nk, means, reg_covar):\n",
        "    \"\"\"Estimate the full covariance matrices.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    resp : array-like of shape (n_samples, n_components)\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "    nk : array-like of shape (n_components,)\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "\n",
        "    reg_covar : float\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    covariances : array, shape (n_components, n_features, n_features)\n",
        "        The covariance matrix of the current components.\n",
        "    \"\"\"\n",
        "    n_components, n_features = means.shape\n",
        "    covariances = np.empty((n_components, n_features, n_features))\n",
        "    for k in range(n_components):\n",
        "        diff = X - means[k]\n",
        "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
        "        covariances[k].flat[::n_features + 1] += reg_covar\n",
        "    return covariances\n",
        "\n",
        "\n",
        "def _estimate_gaussian_covariances_tied(resp, X, nk, means, reg_covar):\n",
        "    \"\"\"Estimate the tied covariance matrix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    resp : array-like of shape (n_samples, n_components)\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "    nk : array-like of shape (n_components,)\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "\n",
        "    reg_covar : float\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    covariance : array, shape (n_features, n_features)\n",
        "        The tied covariance matrix of the components.\n",
        "    \"\"\"\n",
        "    avg_X2 = np.dot(X.T, X)\n",
        "    avg_means2 = np.dot(nk * means.T, means)\n",
        "    covariance = avg_X2 - avg_means2\n",
        "    covariance /= nk.sum()\n",
        "    covariance.flat[::len(covariance) + 1] += reg_covar\n",
        "    return covariance\n",
        "\n",
        "\n",
        "def _estimate_gaussian_covariances_diag(resp, X, nk, means, reg_covar):\n",
        "    \"\"\"Estimate the diagonal covariance vectors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    responsibilities : array-like of shape (n_samples, n_components)\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "    nk : array-like of shape (n_components,)\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "\n",
        "    reg_covar : float\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    covariances : array, shape (n_components, n_features)\n",
        "        The covariance vector of the current components.\n",
        "    \"\"\"\n",
        "    avg_X2 = np.dot(resp.T, X * X) / nk[:, np.newaxis]\n",
        "    avg_means2 = means**2\n",
        "    avg_X_means = means * np.dot(resp.T, X) / nk[:, np.newaxis]\n",
        "    return avg_X2 - 2 * avg_X_means + avg_means2 + reg_covar\n",
        "\n",
        "\n",
        "def _estimate_gaussian_covariances_spherical(resp, X, nk, means, reg_covar):\n",
        "    \"\"\"Estimate the spherical variance values.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    responsibilities : array-like of shape (n_samples, n_components)\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "    nk : array-like of shape (n_components,)\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "\n",
        "    reg_covar : float\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    variances : array, shape (n_components,)\n",
        "        The variance values of each components.\n",
        "    \"\"\"\n",
        "    return _estimate_gaussian_covariances_diag(resp, X, nk, means,\n",
        "                                               reg_covar).mean(1)\n",
        "\n",
        "\n",
        "def _estimate_gaussian_parameters(X, resp, reg_covar, covariance_type, B=None):\n",
        "    \"\"\"Estimate the Gaussian distribution parameters.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "        The input data array.\n",
        "\n",
        "    resp : array-like of shape (n_samples, n_components)\n",
        "        The responsibilities for each data sample in X.\n",
        "\n",
        "    reg_covar : float\n",
        "        The regularization added to the diagonal of the covariance matrices.\n",
        "\n",
        "    covariance_type : {'full', 'tied', 'diag', 'spherical'}\n",
        "        The type of precision matrices.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    nk : array-like of shape (n_components,)\n",
        "        The numbers of data samples in the current components.\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "        The centers of the current components.\n",
        "\n",
        "    covariances : array-like\n",
        "        The covariance matrix of the current components.\n",
        "        The shape depends of the covariance_type.\n",
        "    \"\"\"\n",
        "    # print(\"Doing the thing..\")\n",
        "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
        "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
        "\n",
        "    # frankie\n",
        "    # get the mins for the marker genes\n",
        "    # ct_mins = [means[:, i].min() for i in B]\n",
        "    marker_gene_indices = [set(np.where(i)[0]) for i in B]\n",
        "    ct_mins = [means[i][B[i]].min() for i in range(means.shape[0])]\n",
        "    marker_gene_indices = [set(B[i]) for i in range(means.shape[0])]\n",
        "    # modify based on the min/f\n",
        "    f = 2.\n",
        "    for idx, i in enumerate(means):\n",
        "        ct_min = ct_mins[idx]\n",
        "        betas = means[idx]\n",
        "        for jdx, b in enumerate(betas):\n",
        "            if jdx not in marker_gene_indices[idx]:\n",
        "                new = min(b, ct_min / f)\n",
        "                means[idx][jdx] = new\n",
        "\n",
        "    covariances = {\n",
        "        \"full\": _estimate_gaussian_covariances_full,\n",
        "        \"tied\": _estimate_gaussian_covariances_tied,\n",
        "        \"diag\": _estimate_gaussian_covariances_diag,\n",
        "        \"spherical\": _estimate_gaussian_covariances_spherical,\n",
        "    }[covariance_type](resp, X, nk, means, reg_covar)\n",
        "    return nk, means, covariances\n",
        "\n",
        "\n",
        "def _compute_precision_cholesky(covariances, covariance_type):\n",
        "    \"\"\"Compute the Cholesky decomposition of the precisions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    covariances : array-like\n",
        "        The covariance matrix of the current components.\n",
        "        The shape depends of the covariance_type.\n",
        "\n",
        "    covariance_type : {'full', 'tied', 'diag', 'spherical'}\n",
        "        The type of precision matrices.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    precisions_cholesky : array-like\n",
        "        The cholesky decomposition of sample precisions of the current\n",
        "        components. The shape depends of the covariance_type.\n",
        "    \"\"\"\n",
        "    estimate_precision_error_message = (\n",
        "        \"Fitting the mixture model failed because some components have \"\n",
        "        \"ill-defined empirical covariance (for instance caused by singleton \"\n",
        "        \"or collapsed samples). Try to decrease the number of components, \"\n",
        "        \"or increase reg_covar.\")\n",
        "\n",
        "    if covariance_type == \"full\":\n",
        "        n_components, n_features, _ = covariances.shape\n",
        "        precisions_chol = np.empty((n_components, n_features, n_features))\n",
        "        for k, covariance in enumerate(covariances):\n",
        "            try:\n",
        "                cov_chol = linalg.cholesky(covariance, lower=True)\n",
        "            except linalg.LinAlgError:\n",
        "                raise ValueError(estimate_precision_error_message)\n",
        "            precisions_chol[k] = linalg.solve_triangular(cov_chol,\n",
        "                                                         np.eye(n_features),\n",
        "                                                         lower=True).T\n",
        "    elif covariance_type == \"tied\":\n",
        "        _, n_features = covariances.shape\n",
        "        try:\n",
        "            cov_chol = linalg.cholesky(covariances, lower=True)\n",
        "        except linalg.LinAlgError:\n",
        "            raise ValueError(estimate_precision_error_message)\n",
        "        precisions_chol = linalg.solve_triangular(cov_chol,\n",
        "                                                  np.eye(n_features),\n",
        "                                                  lower=True).T\n",
        "    else:\n",
        "        if np.any(np.less_equal(covariances, 0.0)):\n",
        "            raise ValueError(estimate_precision_error_message)\n",
        "        precisions_chol = 1.0 / np.sqrt(covariances)\n",
        "    return precisions_chol\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Gaussian mixture probability estimators\n",
        "def _compute_log_det_cholesky(matrix_chol, covariance_type, n_features):\n",
        "    \"\"\"Compute the log-det of the cholesky decomposition of matrices.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    matrix_chol : array-like\n",
        "        Cholesky decompositions of the matrices.\n",
        "        'full' : shape of (n_components, n_features, n_features)\n",
        "        'tied' : shape of (n_features, n_features)\n",
        "        'diag' : shape of (n_components, n_features)\n",
        "        'spherical' : shape of (n_components,)\n",
        "\n",
        "    covariance_type : {'full', 'tied', 'diag', 'spherical'}\n",
        "\n",
        "    n_features : int\n",
        "        Number of features.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    log_det_precision_chol : array-like of shape (n_components,)\n",
        "        The determinant of the precision matrix for each component.\n",
        "    \"\"\"\n",
        "    if covariance_type == \"full\":\n",
        "        n_components, _, _ = matrix_chol.shape\n",
        "        log_det_chol = np.sum(\n",
        "            np.log(matrix_chol.reshape(n_components, -1)[:, ::n_features + 1]),\n",
        "            1)\n",
        "\n",
        "    elif covariance_type == \"tied\":\n",
        "        log_det_chol = np.sum(np.log(np.diag(matrix_chol)))\n",
        "\n",
        "    elif covariance_type == \"diag\":\n",
        "        log_det_chol = np.sum(np.log(matrix_chol), axis=1)\n",
        "\n",
        "    else:\n",
        "        log_det_chol = n_features * (np.log(matrix_chol))\n",
        "\n",
        "    return log_det_chol\n",
        "\n",
        "\n",
        "def _estimate_log_gaussian_prob(X, means, precisions_chol, covariance_type):\n",
        "    \"\"\"Estimate the log Gaussian probability.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "    means : array-like of shape (n_components, n_features)\n",
        "\n",
        "    precisions_chol : array-like\n",
        "        Cholesky decompositions of the precision matrices.\n",
        "        'full' : shape of (n_components, n_features, n_features)\n",
        "        'tied' : shape of (n_features, n_features)\n",
        "        'diag' : shape of (n_components, n_features)\n",
        "        'spherical' : shape of (n_components,)\n",
        "\n",
        "    covariance_type : {'full', 'tied', 'diag', 'spherical'}\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    log_prob : array, shape (n_samples, n_components)\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "    n_components, _ = means.shape\n",
        "    # det(precision_chol) is half of det(precision)\n",
        "    log_det = _compute_log_det_cholesky(precisions_chol, covariance_type,\n",
        "                                        n_features)\n",
        "\n",
        "    if covariance_type == \"full\":\n",
        "        log_prob = np.empty((n_samples, n_components))\n",
        "        for k, (mu, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
        "            y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
        "            log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
        "\n",
        "    elif covariance_type == \"tied\":\n",
        "        log_prob = np.empty((n_samples, n_components))\n",
        "        for k, mu in enumerate(means):\n",
        "            y = np.dot(X, precisions_chol) - np.dot(mu, precisions_chol)\n",
        "            log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
        "\n",
        "    elif covariance_type == \"diag\":\n",
        "        precisions = precisions_chol**2\n",
        "        log_prob = (np.sum((means**2 * precisions), 1) -\n",
        "                    2.0 * np.dot(X, (means * precisions).T) +\n",
        "                    np.dot(X**2, precisions.T))\n",
        "\n",
        "    elif covariance_type == \"spherical\":\n",
        "        precisions = precisions_chol**2\n",
        "        log_prob = (np.sum(means**2, 1) * precisions -\n",
        "                    2 * np.dot(X, means.T * precisions) +\n",
        "                    np.outer(row_norms(X, squared=True), precisions))\n",
        "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
        "\n",
        "\n",
        "class ImprovedGaussianMixture(BaseMixture):\n",
        "    \"\"\"Gaussian Mixture.\n",
        "\n",
        "    Representation of a Gaussian mixture model probability distribution.\n",
        "    This class allows to estimate the parameters of a Gaussian mixture\n",
        "    distribution.\n",
        "\n",
        "    Read more in the :ref:`User Guide <gmm>`.\n",
        "\n",
        "    .. versionadded:: 0.18\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_components : int, default=1\n",
        "        The number of mixture components.\n",
        "\n",
        "    covariance_type : {'full', 'tied', 'diag', 'spherical'}, default='full'\n",
        "        String describing the type of covariance parameters to use.\n",
        "        Must be one of:\n",
        "\n",
        "        'full'\n",
        "            each component has its own general covariance matrix\n",
        "        'tied'\n",
        "            all components share the same general covariance matrix\n",
        "        'diag'\n",
        "            each component has its own diagonal covariance matrix\n",
        "        'spherical'\n",
        "            each component has its own single variance\n",
        "\n",
        "    tol : float, default=1e-3\n",
        "        The convergence threshold. EM iterations will stop when the\n",
        "        lower bound average gain is below this threshold.\n",
        "\n",
        "    reg_covar : float, default=1e-6\n",
        "        Non-negative regularization added to the diagonal of covariance.\n",
        "        Allows to assure that the covariance matrices are all positive.\n",
        "\n",
        "    max_iter : int, default=100\n",
        "        The number of EM iterations to perform.\n",
        "\n",
        "    n_init : int, default=1\n",
        "        The number of initializations to perform. The best results are kept.\n",
        "\n",
        "    init_params : {'kmeans', 'random'}, default='kmeans'\n",
        "        The method used to initialize the weights, the means and the\n",
        "        precisions.\n",
        "        Must be one of::\n",
        "\n",
        "            'kmeans' : responsibilities are initialized using kmeans.\n",
        "            'random' : responsibilities are initialized randomly.\n",
        "\n",
        "    weights_init : array-like of shape (n_components, ), default=None\n",
        "        The user-provided initial weights.\n",
        "        If it is None, weights are initialized using the `init_params` method.\n",
        "\n",
        "    means_init : array-like of shape (n_components, n_features), default=None\n",
        "        The user-provided initial means,\n",
        "        If it is None, means are initialized using the `init_params` method.\n",
        "\n",
        "    precisions_init : array-like, default=None\n",
        "        The user-provided initial precisions (inverse of the covariance\n",
        "        matrices).\n",
        "        If it is None, precisions are initialized using the 'init_params'\n",
        "        method.\n",
        "        The shape depends on 'covariance_type'::\n",
        "\n",
        "            (n_components,)                        if 'spherical',\n",
        "            (n_features, n_features)               if 'tied',\n",
        "            (n_components, n_features)             if 'diag',\n",
        "            (n_components, n_features, n_features) if 'full'\n",
        "\n",
        "    random_state : int, RandomState instance or None, default=None\n",
        "        Controls the random seed given to the method chosen to initialize the\n",
        "        parameters (see `init_params`).\n",
        "        In addition, it controls the generation of random samples from the\n",
        "        fitted distribution (see the method `sample`).\n",
        "        Pass an int for reproducible output across multiple function calls.\n",
        "        See :term:`Glossary <random_state>`.\n",
        "\n",
        "    warm_start : bool, default=False\n",
        "        If 'warm_start' is True, the solution of the last fitting is used as\n",
        "        initialization for the next call of fit(). This can speed up\n",
        "        convergence when fit is called several times on similar problems.\n",
        "        In that case, 'n_init' is ignored and only a single initialization\n",
        "        occurs upon the first call.\n",
        "        See :term:`the Glossary <warm_start>`.\n",
        "\n",
        "    verbose : int, default=0\n",
        "        Enable verbose output. If 1 then it prints the current\n",
        "        initialization and each iteration step. If greater than 1 then\n",
        "        it prints also the log probability and the time needed\n",
        "        for each step.\n",
        "\n",
        "    verbose_interval : int, default=10\n",
        "        Number of iteration done before the next print.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    weights_ : array-like of shape (n_components,)\n",
        "        The weights of each mixture components.\n",
        "\n",
        "    means_ : array-like of shape (n_components, n_features)\n",
        "        The mean of each mixture component.\n",
        "\n",
        "    covariances_ : array-like\n",
        "        The covariance of each mixture component.\n",
        "        The shape depends on `covariance_type`::\n",
        "\n",
        "            (n_components,)                        if 'spherical',\n",
        "            (n_features, n_features)               if 'tied',\n",
        "            (n_components, n_features)             if 'diag',\n",
        "            (n_components, n_features, n_features) if 'full'\n",
        "\n",
        "    precisions_ : array-like\n",
        "        The precision matrices for each component in the mixture. A precision\n",
        "        matrix is the inverse of a covariance matrix. A covariance matrix is\n",
        "        symmetric positive definite so the mixture of Gaussian can be\n",
        "        equivalently parameterized by the precision matrices. Storing the\n",
        "        precision matrices instead of the covariance matrices makes it more\n",
        "        efficient to compute the log-likelihood of new samples at test time.\n",
        "        The shape depends on `covariance_type`::\n",
        "\n",
        "            (n_components,)                        if 'spherical',\n",
        "            (n_features, n_features)               if 'tied',\n",
        "            (n_components, n_features)             if 'diag',\n",
        "            (n_components, n_features, n_features) if 'full'\n",
        "\n",
        "    precisions_cholesky_ : array-like\n",
        "        The cholesky decomposition of the precision matrices of each mixture\n",
        "        component. A precision matrix is the inverse of a covariance matrix.\n",
        "        A covariance matrix is symmetric positive definite so the mixture of\n",
        "        Gaussian can be equivalently parameterized by the precision matrices.\n",
        "        Storing the precision matrices instead of the covariance matrices makes\n",
        "        it more efficient to compute the log-likelihood of new samples at test\n",
        "        time. The shape depends on `covariance_type`::\n",
        "\n",
        "            (n_components,)                        if 'spherical',\n",
        "            (n_features, n_features)               if 'tied',\n",
        "            (n_components, n_features)             if 'diag',\n",
        "            (n_components, n_features, n_features) if 'full'\n",
        "\n",
        "    converged_ : bool\n",
        "        True when convergence was reached in fit(), False otherwise.\n",
        "\n",
        "    n_iter_ : int\n",
        "        Number of step used by the best fit of EM to reach the convergence.\n",
        "\n",
        "    lower_bound_ : float\n",
        "        Lower bound value on the log-likelihood (of the training data with\n",
        "        respect to the model) of the best fit of EM.\n",
        "\n",
        "    n_features_in_ : int\n",
        "        Number of features seen during :term:`fit`.\n",
        "\n",
        "        .. versionadded:: 0.24\n",
        "\n",
        "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
        "        Names of features seen during :term:`fit`. Defined only when `X`\n",
        "        has feature names that are all strings.\n",
        "\n",
        "        .. versionadded:: 1.0\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    BayesianGaussianMixture : Gaussian mixture model fit with a variational\n",
        "        inference.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import numpy as np\n",
        "    >>> from sklearn.mixture import GaussianMixture\n",
        "    >>> X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n",
        "    >>> gm = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
        "    >>> gm.means_\n",
        "    array([[10.,  2.],\n",
        "           [ 1.,  2.]])\n",
        "    >>> gm.predict([[0, 0], [12, 3]])\n",
        "    array([1, 0])\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_components=1,\n",
        "        *,\n",
        "        covariance_type=\"full\",\n",
        "        tol=1e-3,\n",
        "        reg_covar=1e-6,\n",
        "        max_iter=100,\n",
        "        n_init=1,\n",
        "        init_params=\"kmeans\",\n",
        "        weights_init=None,\n",
        "        means_init=None,\n",
        "        precisions_init=None,\n",
        "        random_state=None,\n",
        "        warm_start=False,\n",
        "        verbose=0,\n",
        "        verbose_interval=10,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            n_components=n_components,\n",
        "            tol=tol,\n",
        "            reg_covar=reg_covar,\n",
        "            max_iter=max_iter,\n",
        "            n_init=n_init,\n",
        "            init_params=init_params,\n",
        "            random_state=random_state,\n",
        "            warm_start=warm_start,\n",
        "            verbose=verbose,\n",
        "            verbose_interval=verbose_interval,\n",
        "        )\n",
        "\n",
        "        self.covariance_type = covariance_type\n",
        "        self.weights_init = weights_init\n",
        "        self.means_init = means_init\n",
        "        self.precisions_init = precisions_init\n",
        "\n",
        "    def _check_parameters(self, X):\n",
        "        \"\"\"Check the Gaussian mixture parameters are well defined.\"\"\"\n",
        "        _, n_features = X.shape\n",
        "        if self.covariance_type not in [\"spherical\", \"tied\", \"diag\", \"full\"]:\n",
        "            raise ValueError(\"Invalid value for 'covariance_type': %s \"\n",
        "                             \"'covariance_type' should be in \"\n",
        "                             \"['spherical', 'tied', 'diag', 'full']\" %\n",
        "                             self.covariance_type)\n",
        "\n",
        "        if self.weights_init is not None:\n",
        "            self.weights_init = _check_weights(self.weights_init,\n",
        "                                               self.n_components)\n",
        "\n",
        "        if self.means_init is not None:\n",
        "            self.means_init = _check_means(self.means_init, self.n_components,\n",
        "                                           n_features)\n",
        "\n",
        "        if self.precisions_init is not None:\n",
        "            self.precisions_init = _check_precisions(\n",
        "                self.precisions_init,\n",
        "                self.covariance_type,\n",
        "                self.n_components,\n",
        "                n_features,\n",
        "            )\n",
        "\n",
        "    def _initialize(self, X, resp, B=None):\n",
        "        \"\"\"Initialization of the Gaussian mixture parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        resp : array-like of shape (n_samples, n_components)\n",
        "        \"\"\"\n",
        "        n_samples, _ = X.shape\n",
        "\n",
        "        weights, means, covariances = _estimate_gaussian_parameters(\n",
        "            X, resp, self.reg_covar, self.covariance_type, B=B)\n",
        "        weights /= n_samples\n",
        "\n",
        "        self.weights_ = weights if self.weights_init is None else self.weights_init\n",
        "        self.means_ = means if self.means_init is None else self.means_init\n",
        "\n",
        "        if self.precisions_init is None:\n",
        "            self.covariances_ = covariances\n",
        "            self.precisions_cholesky_ = _compute_precision_cholesky(\n",
        "                covariances, self.covariance_type)\n",
        "        elif self.covariance_type == \"full\":\n",
        "            self.precisions_cholesky_ = np.array([\n",
        "                linalg.cholesky(prec_init, lower=True)\n",
        "                for prec_init in self.precisions_init\n",
        "            ])\n",
        "        elif self.covariance_type == \"tied\":\n",
        "            self.precisions_cholesky_ = linalg.cholesky(self.precisions_init,\n",
        "                                                        lower=True)\n",
        "        else:\n",
        "            self.precisions_cholesky_ = self.precisions_init\n",
        "\n",
        "    def _m_step(self, X, log_resp, B=None):\n",
        "        \"\"\"M step.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        log_resp : array-like of shape (n_samples, n_components)\n",
        "            Logarithm of the posterior probabilities (or responsibilities) of\n",
        "            the point of each sample in X.\n",
        "        \"\"\"\n",
        "        n_samples, _ = X.shape\n",
        "        self.weights_, self.means_, self.covariances_ = _estimate_gaussian_parameters(\n",
        "            X, np.exp(log_resp), self.reg_covar, self.covariance_type, B=B)\n",
        "        self.weights_ /= n_samples\n",
        "        self.precisions_cholesky_ = _compute_precision_cholesky(\n",
        "            self.covariances_, self.covariance_type)\n",
        "\n",
        "    def _estimate_log_prob(self, X):\n",
        "        return _estimate_log_gaussian_prob(X, self.means_,\n",
        "                                           self.precisions_cholesky_,\n",
        "                                           self.covariance_type)\n",
        "\n",
        "    def _estimate_log_weights(self):\n",
        "        return np.log(self.weights_)\n",
        "\n",
        "    def _compute_lower_bound(self, _, log_prob_norm):\n",
        "        return log_prob_norm\n",
        "\n",
        "    def _get_parameters(self):\n",
        "        return (\n",
        "            self.weights_,\n",
        "            self.means_,\n",
        "            self.covariances_,\n",
        "            self.precisions_cholesky_,\n",
        "        )\n",
        "\n",
        "    def _set_parameters(self, params):\n",
        "        (\n",
        "            self.weights_,\n",
        "            self.means_,\n",
        "            self.covariances_,\n",
        "            self.precisions_cholesky_,\n",
        "        ) = params\n",
        "\n",
        "        # Attributes computation\n",
        "        _, n_features = self.means_.shape\n",
        "\n",
        "        if self.covariance_type == \"full\":\n",
        "            self.precisions_ = np.empty(self.precisions_cholesky_.shape)\n",
        "            for k, prec_chol in enumerate(self.precisions_cholesky_):\n",
        "                self.precisions_[k] = np.dot(prec_chol, prec_chol.T)\n",
        "\n",
        "        elif self.covariance_type == \"tied\":\n",
        "            self.precisions_ = np.dot(self.precisions_cholesky_,\n",
        "                                      self.precisions_cholesky_.T)\n",
        "        else:\n",
        "            self.precisions_ = self.precisions_cholesky_**2\n",
        "\n",
        "    def _n_parameters(self):\n",
        "        \"\"\"Return the number of free parameters in the model.\"\"\"\n",
        "        _, n_features = self.means_.shape\n",
        "        if self.covariance_type == \"full\":\n",
        "            cov_params = self.n_components * n_features * (n_features +\n",
        "                                                           1) / 2.0\n",
        "        elif self.covariance_type == \"diag\":\n",
        "            cov_params = self.n_components * n_features\n",
        "        elif self.covariance_type == \"tied\":\n",
        "            cov_params = n_features * (n_features + 1) / 2.0\n",
        "        elif self.covariance_type == \"spherical\":\n",
        "            cov_params = self.n_components\n",
        "        mean_params = n_features * self.n_components\n",
        "        return int(cov_params + mean_params + self.n_components - 1)\n",
        "\n",
        "    def bic(self, X):\n",
        "        \"\"\"Bayesian information criterion for the current model on the input X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array of shape (n_samples, n_dimensions)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bic : float\n",
        "            The lower the better.\n",
        "        \"\"\"\n",
        "        return -2 * self.score(X) * X.shape[0] + self._n_parameters() * np.log(\n",
        "            X.shape[0])\n",
        "\n",
        "    def aic(self, X):\n",
        "        \"\"\"Akaike information criterion for the current model on the input X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array of shape (n_samples, n_dimensions)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        aic : float\n",
        "            The lower the better.\n",
        "        \"\"\"\n",
        "        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvjgUAvbKyni"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.io import mmread, mmwrite\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KDTree\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from upsetplot import from_memberships, plot as upsetplot, from_contents\n",
        "\n",
        "fsize=20\n",
        "\n",
        "plt.rcParams.update({'font.size': fsize})\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCbXVL3JYEh"
      },
      "source": [
        "organ = \"blood\"\n",
        "observation = \"GSM2560248\"\n",
        "\n",
        "base_data = f\"human/data/{organ}/{observation}\"\n",
        "base_mark = f\"human/markers/{organ}/\"\n",
        "\n",
        "markers_fn = os.path.join(base_mark, \"markers.txt\")\n",
        "matrix_fn = os.path.join(base_data, \"matrix.mtx\")\n",
        "genes_fn = os.path.join(base_data, \"genes.txt\")\n",
        "\n",
        "labels_fn = os.path.join(base_data, \"labels.txt\")\n",
        "\n",
        "# celltype labels for GSM\n",
        "# labels = pd.Series(GSM['cluster_assignment']).str.strip(' ')\n",
        "# z = labels.astype(\"category\").cat.codes.values\n",
        "# celltype for Standard\n",
        "# labels = pd.read_csv(labels_fname, sep=\"\\t\", header=None, names=[\"cell\", \"celltype\"])\n",
        "# z = labels[\"celltype\"].astype(\"category\").cat.codes.values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyk7X06YKxeq"
      },
      "source": [
        "!gunzip $base_data/*.gz"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Vr7YayK3om"
      },
      "source": [
        "# index the markers\n",
        "!./index.py $markers_fn ./"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930971oeLD7S"
      },
      "source": [
        "# get the gene ids\n",
        "!./select.py $markers_fn $genes_fn ./"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2HqIAdUpRoq"
      },
      "source": [
        "Read in matrix, select columns, write to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPrVkb-LK0R"
      },
      "source": [
        "def read_markers_ec(fname, markers_ec=defaultdict(list)):\n",
        "  with open(fname, 'r') as f:\n",
        "    for idx, line in enumerate(f.readlines()):\n",
        "      ct_id, gene_ids = line.strip().split('\\t')\n",
        "      markers_ec[int(ct_id)] = [int(i) for i in gene_ids.split(',')]\n",
        "\n",
        "markers_ec = defaultdict(list)\n",
        "read_markers_ec(\"markers.ec\", markers_ec)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NEy7vOtozRT"
      },
      "source": [
        "def read_int_list(fname, lst=[]):\n",
        "  with open(fname) as f:\n",
        "    for idx, i in enumerate(f.readlines()):\n",
        "      lst.append(int(i.strip()))\n",
        "\n",
        "sel = []\n",
        "read_int_list(\"select.txt\", sel)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP4TIEvPpAPv"
      },
      "source": [
        "mtx = mmread(matrix_fn).tocsr()\n",
        "mmwrite(\"matrix_select.mtx\", mtx[:,sel])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFVdm3fOpase",
        "outputId": "b746c5a1-d27f-4451-93dc-b44d8e978168"
      },
      "source": [
        "G = mmread(\"matrix_select.mtx\").toarray()\n",
        "\n",
        "n_clusters = len(markers_ec.keys())\n",
        "n_samples, n_features = G.shape\n",
        "print(n_clusters, *G.shape, sep=\", \")\n",
        "\n",
        "count_mask          = G.sum(1)     > 0\n",
        "genes_detected_mask = (G>0).sum(1) > 0 \n",
        "cells_detected_mask = (G>0).sum(0) > 0 # handle when genes are dropped (remove from markers_ec)\n",
        "mask = np.logical_and(count_mask, genes_detected_mask)\n",
        "\n",
        "G = G[mask]\n",
        "# z = z[mask]\n",
        "\n",
        "drop_genes = np.arange(G.shape[1])[~cells_detected_mask]\n",
        "\n",
        "n_samples, n_features = G.shape\n",
        "print(n_clusters, *G.shape, sep=\", \")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7, 14619, 45\n",
            "7, 14507, 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry6luC-D4-Nn",
        "outputId": "570e568a-c906-445e-e5c7-1bbde8e7611c"
      },
      "source": [
        "print(f\"Genes lost: {G.shape[1] - cells_detected_mask.sum()}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genes lost: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8KBaO0q4e5u",
        "outputId": "e27ae894-1ed6-4fbc-b930-a7e67aa53857"
      },
      "source": [
        "markers_ec"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              "             1: [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
              "             2: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
              "             3: [0, 5, 8, 9, 26, 31, 32, 33, 34, 35, 36],\n",
              "             4: [0, 6, 7, 8, 9, 20, 25, 26, 32, 33, 37],\n",
              "             5: [4, 24, 25, 26, 32, 38, 39, 40, 41, 42, 43],\n",
              "             6: [0, 5, 6, 8, 9, 26, 32, 33, 34, 35, 44]})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCCshdjy4gtF",
        "outputId": "e79c43d6-a6d8-4290-f0b3-7429312682e6"
      },
      "source": [
        "G.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14507, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhq8RoF27QJm",
        "outputId": "93b9c2f9-2a06-4a82-c79b-aded14ce2002"
      },
      "source": [
        "drop_genes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  3, 34, 42])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_YmAsRv2waP"
      },
      "source": [
        "# Quality control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pami1ZW0pur7"
      },
      "source": [
        "# QC\n",
        "# Average fractional amount of UMIs per celltype for the genes that mark that celltype\n",
        "tot = G.sum()\n",
        "d = [(k, (G.sum(0)/tot)[v]*100) for k,v in markers_ec.items()]\n",
        "d = pd.DataFrame(d, columns=[\"group\", \"sum_counts\"])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ__dlCspy1Q",
        "outputId": "b0f1c137-13a5-42b5-d9fe-f5bdc9a7d7a7"
      },
      "source": [
        "[(i.mean(), np.var(i)) for i in d[\"sum_counts\"].tolist()]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4.454445892809297, 27.54729275635468),\n",
              " (1.461943006864378, 0.8626044055124513),\n",
              " (2.0202191050130294, 3.7231574505213443),\n",
              " (4.188666030342881, 28.52228905860543),\n",
              " (3.822517174399487, 18.601124733104758),\n",
              " (2.0267156043993215, 3.8132219187990186),\n",
              " (4.448602887444112, 27.03787828685356)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUXrI5Rn2gfE",
        "outputId": "1348fc8c-fa2d-4d4e-ab9a-6130edd60225"
      },
      "source": [
        "[G.sum(0)[v].tolist() for k,v in markers_ec.items()]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36541, 1011, 0, 0, 9152, 32504, 5962, 3425, 17553, 612, 9118],\n",
              " [612, 1454, 989, 3517, 8311, 5911, 3081, 1830, 4105, 4892, 3329],\n",
              " [9538, 921, 749, 3665, 14874, 10126, 6234, 1653, 2521, 1223, 1050],\n",
              " [36541, 32504, 17553, 612, 10126, 1050, 1575, 2976, 0, 3612, 2415],\n",
              " [36541, 5962, 3425, 17553, 612, 3329, 14874, 10126, 1575, 2976, 2466],\n",
              " [9152, 3665, 14874, 10126, 1575, 1785, 462, 109, 5161, 0, 5814],\n",
              " [36541, 32504, 5962, 17553, 612, 10126, 1575, 2976, 0, 3612, 4265]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqcEiTpp2o2j",
        "outputId": "9a866872-db8e-4af8-9c19-2f62adf05dbb"
      },
      "source": [
        "# number of marker genes per cell type\n",
        "pd.Series(markers_ec).apply(lambda x: len(x))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11\n",
              "1    11\n",
              "2    11\n",
              "3    11\n",
              "4    11\n",
              "5    11\n",
              "6    11\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "eLAc3W-R2t-2",
        "outputId": "378dfe20-eb9a-4790-a7eb-d68beb6200d7"
      },
      "source": [
        "# are marker genes shared between celltypes?\n",
        "fig = plt.figure()\n",
        "upsetplot(from_contents(markers_ec), fig=fig)\n",
        "fig.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x416 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Tm_Du6u43iqH"
      },
      "source": [
        "#@title compute real centroids and marker gene centroids\n",
        "\n",
        "def get_centroids(X, z):\n",
        "  clusters = np.sort(np.unique(z))\n",
        "  \n",
        "  n_clusters, = clusters.shape\n",
        "  _, n_features = X.shape\n",
        "\n",
        "  centroids = np.ones((n_clusters, n_features))\n",
        "  for i, g in enumerate(clusters):\n",
        "    centroids[i] = (X[np.where(z==g)[0]].mean(0))\n",
        "  return centroids\n",
        "\n",
        "def get_marker_centroids(X, markers_ec, method=\"mean\"):\n",
        "  n_clusters = len(list(markers_ec.keys()))\n",
        "  _, n_features = X.shape\n",
        "\n",
        "  marker_centroids = np.ones((n_clusters, n_features))*1e-5\n",
        "\n",
        "  for k, v in markers_ec.items():\n",
        "    submx = X[:, v]\n",
        "    if method == 'max':\n",
        "      repl = submx.max(0)\n",
        "    else:\n",
        "      repl = submx.mean(0)\n",
        "    marker_centroids[k][v] = repl\n",
        "  return marker_centroids"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Pw1qHr2zz6"
      },
      "source": [
        "# get the centroids for the existing data\n",
        "data = {\n",
        "    \"X\": {\n",
        "        \"raw_log1p\": np.log1p(G),\n",
        "    }\n",
        "}\n",
        "\n",
        "data.update({\n",
        "    # \"centroids\": {\n",
        "    #     \"raw_log1p\": get_centroids(data[\"X\"][\"raw_log1p\"], z),\n",
        "    #     },\n",
        "      \"marker_centroids\":{\n",
        "          \"raw_log1p\": get_marker_centroids(data[\"X\"][\"raw_log1p\"], markers_ec, \"mean\"),\n",
        "      }\n",
        "    }\n",
        ")\n",
        "\n",
        "method = \"raw_log1p\"\n",
        "# log(G + 1) recommended by Huber.\n",
        "# for assignment we do\n",
        "# log(G + 1) - log(G + 1).mean(0)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHaE3xpn31q8"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2v4ObXP3ygY"
      },
      "source": [
        "# have to initialize the clusters by first mean centering\n",
        "# alternative is to zscore the means\n",
        "\n",
        "X_mean = data[\"X\"][method].mean(0)\n",
        "X_init = (data[\"X\"][method] - X_mean) \n",
        "centroids_init = get_marker_centroids(X_init, markers_ec, \"max\")\n",
        "\n",
        "tree = KDTree(centroids_init, metric=\"euclidean\")\n",
        "nearest_dist, nearest_ind = tree.query(X_init, k=1)\n",
        "\n",
        "# assign cells to clusters\n",
        "p = 1\n",
        "resp = np.ones((n_samples, n_clusters))*(1-p)/(n_clusters-1)\n",
        "resp[np.arange(n_samples), nearest_ind.flatten()] = p\n",
        "\n",
        "# initialize params\n",
        "nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
        "\n",
        "# then once we have the means, add the previously subtracted means back\n",
        "means_init = np.dot(resp.T, X_init) / nk[:, np.newaxis]\n",
        "means_init += X_mean\n",
        "\n",
        "# alternative to uniform weights is nk / n_samples (using the new assignments)\n",
        "uniform_weights = np.array([1./n_clusters]*n_clusters)\n",
        "\n",
        "# alternative is to compute precisions by first doing M-step to get gaus params\n",
        "identity_precisions = np.repeat(np.array([np.eye(data['X'][method].shape[1])]), n_clusters, 0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgs6m0sZ4QFR"
      },
      "source": [
        "gmm_params = {\n",
        "            \"n_components\": n_clusters,\n",
        "            \"means_init\": None, # to be added\n",
        "            \"weights_init\": None, # to be added\n",
        "            \"precisions_init\": None, # to be added\n",
        "            \"random_state\": 0,\n",
        "            \"reg_covar\": 1e-8,\n",
        "            \"verbose\": 2,\n",
        "            \"n_init\": 1,\n",
        "            \"max_iter\": 100,\n",
        "            \"tol\": 1e-3,\n",
        "            \"init_params\": \"random\"\n",
        "  }\n",
        "\n",
        "params = {**gmm_params, \n",
        "          \"means_init\": means_init, # centroids,\n",
        "          \"weights_init\": uniform_weights, \n",
        "          \"precisions_init\": identity_precisions\n",
        "          }\n",
        "\n",
        "gmm = ImprovedGaussianMixture(**params)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNwwPDSRgg7t"
      },
      "source": [
        "def drop_markers(markers_ec, drop_ids):\n",
        "  for k,v in markers_ec.items():\n",
        "\n",
        "    gidx = len(v)-1\n",
        "    while gidx > -1:\n",
        "      mg = markers_ec[k][gidx]\n",
        "      \n",
        "      if mg in drop_ids:\n",
        "          markers_ec[k].pop(gidx)\n",
        "      else:    \n",
        "        to_sub = 0\n",
        "        for d in drop_ids:\n",
        "          if d < mg:\n",
        "            to_sub += 1\n",
        "        markers_ec[k][gidx] -= to_sub\n",
        "      gidx -= 1\n",
        "\n",
        "drop_ids = set([2, 3, 34, 42])\n",
        "truth = {0: [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
        "        1: [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
        "        2: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
        "        3: [0, 3,  6,  7, 24, 29, 30, 31, 32, 33],\n",
        "        4: [0, 4,  5,  6,  7, 18, 23, 24, 30, 31, 34],\n",
        "        5: [2, 22, 23, 24, 30, 35, 36, 37, 38, 39],\n",
        "        6: [0, 3,  4,  6,  7, 24, 30, 31, 32, 40]}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrWYIwAX0pR"
      },
      "source": [
        "drop_markers(markers_ec, set(drop_genes))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6Y6Mg-YYLuj",
        "outputId": "b18240be-8891-457e-e4df-a09036a4e6b0"
      },
      "source": [
        "markers_ec == truth"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohj75b5I5WiS",
        "outputId": "1f2ba57b-5070-42f9-8076-4dca5aa0f420"
      },
      "source": [
        "print(method, json.dumps(params, indent=4, default=str))\n",
        "\n",
        "labels = gmm.fit_predict(data[\"X\"][method], B=markers_ec)\n",
        "means = gmm.means_\n",
        "prob = gmm.predict_proba(data[\"X\"][method])\n",
        "ent = entropy(prob, axis=1)\n",
        "# rand = rand_score(z, labels)\n",
        "# dist = cdist(gt[\"centroids\"][method], means)#, metric=\"cityblock\")\n",
        "# close = np.argmin(dist, axis=0)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw_log1p {\n",
            "    \"n_components\": 7,\n",
            "    \"means_init\": \"[[ 1.09974277e+00  5.76729882e-02  0.00000000e+00  0.00000000e+00\\n   4.23841963e-01  1.00506107e+00  2.73807302e-01  1.66806590e-01\\n   8.34235693e-01  1.45832086e-02  3.93190199e-01  7.01717055e-02\\n   4.97957220e-02  1.64738927e-01  1.62413351e-01  2.70056977e-01\\n   1.50911327e-01  9.30771770e-02  1.76241006e-01  2.25460876e-01\\n   1.32112585e-01  4.00072854e-01  3.85363839e-02  3.36905344e-02\\n   1.63492139e-01  5.64530706e-01  3.56618868e-01  2.90333285e-01\\n   7.14629474e-02  1.03491763e-01  3.71381357e-02  2.80061430e-02\\n   4.36140456e-02  1.07739808e-01  0.00000000e+00  1.25557238e-01\\n   8.55407517e-02  4.19120909e-02  7.42566752e-02  1.92181599e-02\\n   2.85381597e-03  2.36637757e-01  0.00000000e+00  2.09110355e-01\\n   1.76334191e-01]\\n [ 7.46743255e-01  3.36680508e-01  0.00000000e+00  0.00000000e+00\\n   5.07997080e-01  6.58639232e-01  1.45925722e-01  1.09444292e-01\\n   6.59468093e-01  3.64814306e-02  9.50490676e-01  7.29628611e-02\\n   7.29628611e-02  2.98050552e-01  4.09850141e+00  2.40228852e-01\\n   1.88606260e-01  1.67265991e-01  1.09444292e-01  5.19087661e-01\\n   7.29628611e-02  5.58136995e-01 -6.93889390e-18  0.00000000e+00\\n   2.18888583e-01  6.53922803e-01  3.86154574e-01  2.25087690e-01\\n   0.00000000e+00  9.43031300e-02  7.29628611e-02  6.93889390e-18\\n   3.64814306e-02  1.30784561e-01  0.00000000e+00  1.09444292e-01\\n   2.03747422e-01  0.00000000e+00  0.00000000e+00  3.33049304e-01\\n   0.00000000e+00  1.09444292e-01  0.00000000e+00  1.67265991e-01\\n   2.09946529e-01]\\n [ 9.15996969e-01  4.46115783e-02  0.00000000e+00  0.00000000e+00\\n   2.61213790e-01  9.10859717e-01  2.88396303e-01  2.30696782e-01\\n   4.89657989e-01  1.01112413e-01  5.70617207e-01  5.84166152e-02\\n   9.10481792e-02  2.14412373e-01  2.93585123e-01  2.82111650e-01\\n   1.37685553e-01  8.31197550e-02  1.45097655e-01  6.64670108e-01\\n   6.15854631e-01  7.26350717e-01  6.38656667e-02  1.55051874e-01\\n   4.49119989e-01  1.26762786e+00  1.06614968e+00  7.60090340e-01\\n   3.11255943e-01  3.02333098e-01  3.91625269e-02  1.34715874e-01\\n   1.42555537e-01  2.60542233e-01  0.00000000e+00  4.30541087e-01\\n   1.78811130e-01  1.76346120e-01  2.83243054e-01  3.20462278e-02\\n   3.75642932e-02  2.92291388e-01  0.00000000e+00  2.41407291e-01\\n   3.63708455e-01]\\n [ 8.31973982e-01  1.11244228e-02  0.00000000e+00  0.00000000e+00\\n   5.74359814e-02  1.26481477e-01  1.65366328e-01  1.01754722e-01\\n   1.91342566e-01  4.12267729e-02  2.13245948e-01  6.22265383e-02\\n   3.25281168e-02  1.29609319e-01  1.04210758e-01  5.59717887e-02\\n   1.09079539e-01  6.46318850e-02  1.24836195e-01  1.47755954e-01\\n   6.51039612e-02  1.29067177e-01  4.65818215e-02  3.17546896e-02\\n   1.05934363e-01  3.35758541e-01  3.81416192e-01  1.68421293e-01\\n   6.92244940e-02  1.52232430e-01  8.80136220e-02  6.12526688e-02\\n   1.12090341e-01  1.53920105e-01  0.00000000e+00  1.60068157e-01\\n   1.06608127e-01  1.45421954e-02  5.86875056e-02  3.81506134e-03\\n   2.99416640e-03  1.33554205e-01  0.00000000e+00  8.02946842e-02\\n   1.64240503e-01]\\n [ 2.48490665e+00  9.02056208e-17  0.00000000e+00  0.00000000e+00\\n   6.93147181e-01  1.79175947e+00  5.27355937e-16  3.05311332e-16\\n   1.33226763e-15  5.20417043e-17  1.79175947e+00  1.52655666e-16\\n   9.71445147e-17  3.33066907e-16  3.33066907e-16  4.16333634e-16\\n   3.05311332e-16  1.80411242e-16  2.30258509e+00  4.44089210e-16\\n   2.49800181e-16  6.66133815e-16  6.93147181e-01  7.63278329e-17\\n   6.93147181e-01  1.11022302e-15  8.32667268e-16  5.55111512e-16\\n   1.66533454e-16  2.49800181e-16  1.24900090e-16  6.93147181e-01\\n   6.93147181e-01  2.49800181e-16  0.00000000e+00  3.05311332e-16\\n   2.08166817e-16  7.63278329e-17  1.09861229e+00  3.12250226e-17\\n   7.80625564e-18  4.44089210e-16  0.00000000e+00  1.94591015e+00\\n   6.93147181e-01]\\n [ 1.83259078e+00  6.93889390e-18  0.00000000e+00  0.00000000e+00\\n   3.46573590e-01  2.62427405e+00  5.70543524e-01  6.17705303e-01\\n   1.02106080e+00  5.31061905e-01  1.16091268e+00  1.38777878e-17\\n   1.73286795e-01  8.66433976e-02  6.40495497e-01  3.97256729e-01\\n   4.33216988e-01  8.66433976e-02  3.97256729e-01  6.57186922e-01\\n   1.13301973e+00  1.11829685e+00  0.00000000e+00  2.59930193e-01\\n   6.57186922e-01  1.16897999e+00  1.53537921e+00  1.04637634e+00\\n   0.00000000e+00  7.43830319e-01  3.97256729e-01  9.95693197e-01\\n   4.83900126e-01  5.34583265e-01  0.00000000e+00  9.87625881e-01\\n   4.83900126e-01  3.92764890e+00  1.13301973e+00  2.23969934e-01\\n   6.13159347e-01  7.94513458e-01  0.00000000e+00  6.71909801e-01\\n   1.05444365e+00]\\n [ 8.42406389e-01  5.00266610e-03  0.00000000e+00  0.00000000e+00\\n   8.22172434e-01  4.75105062e-02  1.24514421e-01  6.82244669e-02\\n   7.93905906e-02  1.63086081e-02  2.15386315e-01  5.18831226e-02\\n   2.79117191e-02  1.29357161e-01  7.98248184e-02  2.33794163e-02\\n   1.19383660e-01  6.79610314e-02  1.39378296e-01  1.28276384e-01\\n   2.02940237e-02  9.41161345e-02  5.29948262e-02  2.78870426e-02\\n   6.96586558e-02  2.95146566e-01  3.54237706e-01  1.65719132e-01\\n   6.79610314e-02  1.72314055e-02  8.73740509e-02  3.89923543e-02\\n   7.33415099e-02  1.25538918e-02  0.00000000e+00  1.05130382e-01\\n   8.64590033e-02  9.70028691e-03  2.15846716e-02  1.99270782e-03\\n   1.99270782e-03  1.16497319e-01  0.00000000e+00  1.08207299e-01\\n   1.46894700e-01]]\",\n",
            "    \"weights_init\": \"[0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\\n 0.14285714]\",\n",
            "    \"precisions_init\": \"[[[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]\\n\\n [[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]\\n\\n [[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]\\n\\n ...\\n\\n [[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]\\n\\n [[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]\\n\\n [[1. 0. 0. ... 0. 0. 0.]\\n  [0. 1. 0. ... 0. 0. 0.]\\n  [0. 0. 1. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 1. 0. 0.]\\n  [0. 0. 0. ... 0. 1. 0.]\\n  [0. 0. 0. ... 0. 0. 1.]]]\",\n",
            "    \"random_state\": 0,\n",
            "    \"reg_covar\": 1e-08,\n",
            "    \"verbose\": 2,\n",
            "    \"n_init\": 1,\n",
            "    \"max_iter\": 100,\n",
            "    \"tol\": 0.001,\n",
            "    \"init_params\": \"random\"\n",
            "}\n",
            "Initialization 0\n",
            "  Iteration 10\t time lapse 1.87710s\t ll change 0.08555\n",
            "Initialization converged: True\t time lapse 3.23455s\t ll 93.61427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZuLCXC5aQi",
        "outputId": "57cfcca1-0cf6-482b-de24-7ef8adf0f2cf"
      },
      "source": [
        "pd.Series(labels).value_counts()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    8903\n",
              "0    2799\n",
              "3    1458\n",
              "1     500\n",
              "4     499\n",
              "2     264\n",
              "5      84\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "j0spOK0u19fx",
        "outputId": "fedbc885-1c8d-4221-b421-ede37cb19627"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "adj_ent = -np.log10(ent)\n",
        "x = np.sort(adj_ent)[::-1]\n",
        "y = np.arange(ent.shape[0])\n",
        "\n",
        "ax.scatter(x,y)\n",
        "ax.set(**{\n",
        "    \"yscale\": \"symlog\",\n",
        "    \"xlabel\": \"-log10(entropy)\",\n",
        "    \"ylabel\": \"Cell rank\"\n",
        "})\n",
        "\n",
        "elim = 15\n",
        "ecutoff = x[np.where(x > elim)[0][-1]]\n",
        "ax.axvline(x=ecutoff)\n",
        "fig.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log10\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 359,
              "height": 337
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pfrlXj72XOk",
        "outputId": "85a85cb2-80e5-496d-e5cc-c6fbf4f51243"
      },
      "source": [
        "prob[ent==0]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0zHDDb02yHs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}